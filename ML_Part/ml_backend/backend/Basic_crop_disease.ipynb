{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RUN THE MODEL IN THE GOOGLE COLAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtS8yoz6CxAG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip -q install kaggle joblib scikit-image opencv-python scikit-learn numpy\n",
        "\n",
        "import os, glob, zipfile, shutil, numpy as np\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding Kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipvwddTNC-GG"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "!cp /content/kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Necessay files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk0-ZdWKC969",
        "outputId": "e7e7dd1b-26d9-422c-9d23-7ccaa74c52a3"
      },
      "outputs": [],
      "source": [
        "# Create folders\n",
        "os.makedirs(\"/content/data\", exist_ok=True)\n",
        "os.makedirs(\"/content/models_out\", exist_ok=True)\n",
        "\n",
        "# Rice (Bangladesh)\n",
        "!kaggle datasets download -d raihan150146/rice-leaf-diseases-dataset -p /content/data --unzip\n",
        "\n",
        "# Jute (Bangladesh)\n",
        "!kaggle datasets download -d mdsaimunalam/jute-leaf-disease-detection -p /content/data --unzip\n",
        "\n",
        "# Potato (PlantVillage)\n",
        "!kaggle datasets download -d aarishasifkhan/plantvillage-potato-disease-dataset -p /content/data --unzip\n",
        "\n",
        "# Tomato (choose one tomato dataset from Kaggle; here using luisolazo/tomato-diseases)\n",
        "!kaggle datasets download -d luisolazo/tomato-diseases -p /content/data --unzip\n",
        "\n",
        "!ls -lah /content/data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detecting Dataset roots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ITl-buTDMuz",
        "outputId": "166072a5-9293-4fa8-9332-aa4d53d20cc7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMG_EXT = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "def is_class_folder(p: Path) -> bool:\n",
        "    if not p.is_dir():\n",
        "        return False\n",
        "    # class folder contains images directly\n",
        "    for ext in IMG_EXT:\n",
        "        if any(p.glob(f\"*{ext}\")):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def find_dataset_roots(base_dir: str):\n",
        "    base = Path(base_dir)\n",
        "    roots = []\n",
        "    for d in base.rglob(\"*\"):\n",
        "        if d.is_dir():\n",
        "            subdirs = [s for s in d.iterdir() if s.is_dir()]\n",
        "            class_like = [s for s in subdirs if is_class_folder(s)]\n",
        "            if len(class_like) >= 2:  # at least 2 classes\n",
        "                roots.append(d)\n",
        "    # keep only top-most (remove nested duplicates)\n",
        "    roots = sorted(set(roots), key=lambda x: len(str(x)))\n",
        "    filtered = []\n",
        "    for r in roots:\n",
        "        if not any(str(r).startswith(str(x) + \"/\") for x in filtered):\n",
        "            filtered.append(r)\n",
        "    return filtered\n",
        "\n",
        "roots = find_dataset_roots(\"/content/data\")\n",
        "print(\"Detected dataset roots:\\n\")\n",
        "for r in roots:\n",
        "    print(\"-\", r)\n",
        "    # show class folders\n",
        "    classes = [c.name for c in r.iterdir() if c.is_dir() and is_class_folder(c)]\n",
        "    print(\"  classes:\", classes[:10], \"...\" if len(classes) > 10 else \"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxaJmPBADMoU",
        "outputId": "06947714-bb61-450e-9d78-f0818f0811a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data/PlantVillage\n",
            "/content/data/PlantVillage/Potato___healthy\n",
            "/content/data/PlantVillage/Potato___Early_blight\n",
            "/content/data/PlantVillage/Potato___Late_blight\n"
          ]
        }
      ],
      "source": [
        "!find \"/content/data/PlantVillage\" -maxdepth 2 -type d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model For rice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "d88LGRaCJ04u",
        "outputId": "774423d5-feeb-46d2-ddff-82244106ea9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from skimage.feature import hog\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "\n",
        "IMG_EXT = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "def extract_features(img_bgr, size=(128,128)):\n",
        "    img = cv2.resize(img_bgr, size, interpolation=cv2.INTER_AREA)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    hog_feat = hog(gray, orientations=9, pixels_per_cell=(8,8),\n",
        "                   cells_per_block=(2,2), block_norm=\"L2-Hys\", feature_vector=True)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv],[0,1,2],None,[8,8,8],[0,180,0,256,0,256]).flatten()\n",
        "    hist = hist / (hist.sum() + 1e-8)\n",
        "    return np.concatenate([hog_feat, hist]).astype(np.float32)\n",
        "\n",
        "def folder_has_images(p: Path) -> bool:\n",
        "    if not p.is_dir(): return False\n",
        "    for ext in IMG_EXT:\n",
        "        if any(p.glob(f\"*{ext}\")):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def find_best_dataset_root(base_dir: str, crop_prefix=None):\n",
        "    \"\"\"\n",
        "    Finds a directory D such that D has >=2 subfolders, and each subfolder contains images.\n",
        "    If crop_prefix is given (PlantVillage), it filters class folders by that prefix.\n",
        "    \"\"\"\n",
        "    base = Path(base_dir)\n",
        "    candidates = []\n",
        "    for d in base.rglob(\"*\"):\n",
        "        if not d.is_dir():\n",
        "            continue\n",
        "        subdirs = [s for s in d.iterdir() if s.is_dir()]\n",
        "        if crop_prefix:\n",
        "            subdirs = [s for s in subdirs if s.name.lower().startswith(crop_prefix.lower())]\n",
        "        class_like = [s for s in subdirs if folder_has_images(s)]\n",
        "        if len(class_like) >= 2:\n",
        "            # score: total images in class folders (bigger is better)\n",
        "            total_imgs = 0\n",
        "            for c in class_like:\n",
        "                for ext in IMG_EXT:\n",
        "                    total_imgs += len(list(c.glob(f\"*{ext}\")))\n",
        "            candidates.append((total_imgs, d, class_like))\n",
        "\n",
        "    if not candidates:\n",
        "        return None\n",
        "\n",
        "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "    total_imgs, best_root, best_classes = candidates[0]\n",
        "    print(\"Auto-selected dataset root:\", best_root)\n",
        "    print(\"total images:\", total_imgs)\n",
        "    print(\"example class folders:\", [c.name for c in best_classes[:10]])\n",
        "    return str(best_root)\n",
        "\n",
        "def load_dataset(root_dir: str, crop_prefix=None, limit_per_class=None):\n",
        "    root = Path(root_dir)\n",
        "    class_dirs = [d for d in root.iterdir() if d.is_dir()]\n",
        "    if crop_prefix:\n",
        "        class_dirs = [d for d in class_dirs if d.name.lower().startswith(crop_prefix.lower())]\n",
        "\n",
        "    X, y = [], []\n",
        "    for cdir in class_dirs:\n",
        "        files = []\n",
        "        for ext in IMG_EXT:\n",
        "            files += list(cdir.glob(f\"*{ext}\"))\n",
        "        if not files:\n",
        "            continue\n",
        "        if limit_per_class:\n",
        "            files = files[:limit_per_class]\n",
        "        for fp in files:\n",
        "            img = cv2.imread(str(fp))\n",
        "            if img is None:\n",
        "                continue\n",
        "            X.append(extract_features(img))\n",
        "            y.append(cdir.name)\n",
        "\n",
        "    return np.array(X, dtype=np.float32), np.array(y)\n",
        "\n",
        "def train_one_crop_auto(crop_name, base_dir, out_pkl, crop_prefix=None):\n",
        "    print(f\"\\n===== Training: {crop_name} =====\")\n",
        "    print(\"base_dir:\", base_dir, \"prefix:\", crop_prefix)\n",
        "\n",
        "    root = find_best_dataset_root(base_dir, crop_prefix=crop_prefix)\n",
        "    if root is None:\n",
        "        raise ValueError(f\"Could not find class folders with images inside: {base_dir}\")\n",
        "\n",
        "    X, y = load_dataset(root, crop_prefix=crop_prefix)\n",
        "    print(\"Samples:\", len(y))\n",
        "    if len(y) < 10:\n",
        "        raise ValueError(\"Too few images found. Check dataset extraction path.\")\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = scaler.fit_transform(X_train)\n",
        "    X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "    models = {\n",
        "        \"LinearSVC\": LinearSVC(),\n",
        "        \"LogReg\": LogisticRegression(max_iter=5000),\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
        "    }\n",
        "\n",
        "    best_name, best_acc, best_model = None, -1, None\n",
        "    for name, m in models.items():\n",
        "        if name == \"RandomForest\":\n",
        "            m.fit(X_train, y_train)\n",
        "            pred = m.predict(X_test)\n",
        "        else:\n",
        "            m.fit(X_train_s, y_train)\n",
        "            pred = m.predict(X_test_s)\n",
        "\n",
        "        acc = accuracy_score(y_test, pred)\n",
        "        print(f\"{name}: {acc:.4f}\")\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_name, best_model = acc, name, m\n",
        "\n",
        "    bundle = {\n",
        "        \"crop\": crop_name,\n",
        "        \"model_name\": best_name,\n",
        "        \"model\": best_model,\n",
        "        \"scaler\": scaler,\n",
        "        \"label_encoder\": le,\n",
        "        \"dataset_root\": root,\n",
        "        \"feature_info\": {\"img_size\": (128,128), \"hog\": \"9 ori, 8x8, 2x2\", \"hsv_hist\": (8,8,8)},\n",
        "    }\n",
        "    os.makedirs(os.path.dirname(out_pkl), exist_ok=True)\n",
        "    joblib.dump(bundle, out_pkl)\n",
        "    print(\"Saved:\", out_pkl)\n",
        "    print(\"Classes:\", list(le.classes_))\n",
        "\n",
        "# Train using YOUR folder names (works even if nested)\n",
        "train_one_crop_auto(\"rice\",   \"/content/data/Rice leaf disease\", \"/content/models_out/rice_model.pkl\")\n",
        "train_one_crop_auto(\"jute\",   \"/content/data/Jute Leaf Disease Detection\", \"/content/models_out/jute_model.pkl\")\n",
        "\n",
        "# PlantVillage: use prefix filter so it only trains that crop\n",
        "train_one_crop_auto(\"potato\", \"/content/data/PlantVillage\", \"/content/models_out/potato_model.pkl\", crop_prefix=\"Potato___\")\n",
        "train_one_crop_auto(\"tomato\", \"/content/data/PlantVillage\", \"/content/models_out/tomato_model.pkl\", crop_prefix=\"Tomato___\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path for Jute Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoSoHLDcJ010",
        "outputId": "5a4d6e71-8cb9-426c-8338-bf5e12e03780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data/Jute Leaf Disease Detection\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic\n",
            "/content/data/Jute Leaf Disease Detection/Healthy Leaf\n",
            "/content/data/Jute Leaf Disease Detection/Cescospora Leaf Spot\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (27).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (106).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (210).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (137).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (191).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (180).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (146).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (230).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (155).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (202).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (102).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (304).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (322).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (97).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (116).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (225).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (126).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (85).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (207).jpg\n",
            "/content/data/Jute Leaf Disease Detection/Golden Mosaic/Golden_Mosaic (328).jpg\n"
          ]
        }
      ],
      "source": [
        "!find \"/content/data/Jute Leaf Disease Detection\" -maxdepth 3 -type d\n",
        "!find \"/content/data/Jute Leaf Disease Detection\" -type f | head -n 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9fCOZiR4-t0"
      },
      "source": [
        "## Model for Jute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxNRrALiJ0ys",
        "outputId": "0ea0bb43-3875-47ae-a392-8b4d2e06c26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samples: 920 Feature dim: 8612\n",
            "Classes: [np.str_('Cescospora Leaf Spot'), np.str_('Golden Mosaic'), np.str_('Healthy Leaf')]\n",
            "LinearSVC: 0.6902\n",
            "LogReg: 0.6848\n",
            "RandomForest: 0.7663\n",
            "KNN: 0.6250\n",
            "\n",
            "Best model: RandomForest Acc: 0.7663043478260869\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "Cescospora Leaf Spot       0.70      0.53      0.61        62\n",
            "       Golden Mosaic       0.73      0.80      0.76        69\n",
            "        Healthy Leaf       0.85      1.00      0.92        53\n",
            "\n",
            "            accuracy                           0.77       184\n",
            "           macro avg       0.76      0.78      0.76       184\n",
            "        weighted avg       0.76      0.77      0.76       184\n",
            "\n",
            "✅ Saved: /content/models_out/jute_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from skimage.feature import hog\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "\n",
        "EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
        "\n",
        "def extract_features(img_bgr, size=(128,128)):\n",
        "    img = cv2.resize(img_bgr, size, interpolation=cv2.INTER_AREA)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    hog_feat = hog(gray, orientations=9, pixels_per_cell=(8,8),\n",
        "                   cells_per_block=(2,2), block_norm=\"L2-Hys\", feature_vector=True)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv],[0,1,2],None,[8,8,8],[0,180,0,256,0,256]).flatten()\n",
        "    hist = hist / (hist.sum() + 1e-8)\n",
        "    return np.concatenate([hog_feat, hist]).astype(np.float32)\n",
        "\n",
        "def load_class_folder_dataset(root_dir, limit_per_class=None):\n",
        "    root = Path(root_dir)\n",
        "    if not root.exists():\n",
        "        raise FileNotFoundError(root_dir)\n",
        "\n",
        "    class_dirs = [d for d in root.iterdir() if d.is_dir()]\n",
        "    if len(class_dirs) < 2:\n",
        "        raise ValueError(\"Not enough class folders found!\")\n",
        "\n",
        "    X, y = [], []\n",
        "    for cdir in class_dirs:\n",
        "        imgs = [f for f in cdir.glob(\"*\") if f.is_file() and f.suffix.lower() in EXTS]\n",
        "        if not imgs:\n",
        "            # if images are nested deeper, use rglob\n",
        "            imgs = [f for f in cdir.rglob(\"*\") if f.is_file() and f.suffix.lower() in EXTS]\n",
        "\n",
        "        if limit_per_class:\n",
        "            imgs = imgs[:limit_per_class]\n",
        "\n",
        "        for fp in imgs:\n",
        "            img = cv2.imread(str(fp))\n",
        "            if img is None:\n",
        "                continue\n",
        "            X.append(extract_features(img))\n",
        "            y.append(cdir.name)\n",
        "\n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "def train_save(root_dir, out_pkl, crop_name=\"jute\"):\n",
        "    X, y = load_class_folder_dataset(root_dir)\n",
        "    print(\"Samples:\", len(y), \"Feature dim:\", X.shape[1])\n",
        "    print(\"Classes:\", sorted(set(y)))\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = scaler.fit_transform(X_train)\n",
        "    X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "    models = {\n",
        "        \"LinearSVC\": LinearSVC(),\n",
        "        \"LogReg\": LogisticRegression(max_iter=5000),\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
        "    }\n",
        "\n",
        "    best_name, best_acc, best_model = None, -1, None\n",
        "    for name, m in models.items():\n",
        "        if name == \"RandomForest\":\n",
        "            m.fit(X_train, y_train)\n",
        "            pred = m.predict(X_test)\n",
        "        else:\n",
        "            m.fit(X_train_s, y_train)\n",
        "            pred = m.predict(X_test_s)\n",
        "\n",
        "        acc = accuracy_score(y_test, pred)\n",
        "        print(f\"{name}: {acc:.4f}\")\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_name, best_model = acc, name, m\n",
        "\n",
        "    # report best\n",
        "    if best_name == \"RandomForest\":\n",
        "        pred = best_model.predict(X_test)\n",
        "    else:\n",
        "        pred = best_model.predict(X_test_s)\n",
        "\n",
        "    print(\"\\nBest model:\", best_name, \"Acc:\", best_acc)\n",
        "    print(classification_report(y_test, pred, target_names=le.classes_))\n",
        "\n",
        "    bundle = {\n",
        "        \"crop\": crop_name,\n",
        "        \"model_name\": best_name,\n",
        "        \"model\": best_model,\n",
        "        \"scaler\": scaler,\n",
        "        \"label_encoder\": le,\n",
        "        \"dataset_root\": root_dir,\n",
        "        \"feature_info\": {\"img_size\": (128,128), \"hog\": \"9 ori, 8x8, 2x2\", \"hsv_hist\": (8,8,8)},\n",
        "    }\n",
        "\n",
        "    os.makedirs(os.path.dirname(out_pkl), exist_ok=True)\n",
        "    joblib.dump(bundle, out_pkl)\n",
        "    print(\"Saved:\", out_pkl)\n",
        "\n",
        "# Train Jute from your exact folder\n",
        "train_save(\n",
        "    \"/content/data/Jute Leaf Disease Detection\",\n",
        "    \"/content/models_out/jute_model.pkl\",\n",
        "    crop_name=\"jute\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model for Potato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qPXf91aKF3P",
        "outputId": "246e9608-c827-4c33-8b0a-57e3025c6986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Potato classes:\n",
            " - Potato___healthy\n",
            " - Potato___Early_blight\n",
            " - Potato___Late_blight\n",
            "\n",
            "Total samples: 2152 Feature dim: 8612\n",
            "LinearSVC accuracy: 0.9582\n",
            "LogReg accuracy: 0.9513\n",
            "RandomForest accuracy: 0.9629\n",
            "KNN accuracy: 0.7564\n",
            "\n",
            "Best model: RandomForest Acc: 0.962877030162413\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "Potato___Early_blight       0.99      0.96      0.98       200\n",
            " Potato___Late_blight       0.93      0.99      0.96       200\n",
            "     Potato___healthy       1.00      0.77      0.87        31\n",
            "\n",
            "             accuracy                           0.96       431\n",
            "            macro avg       0.97      0.91      0.94       431\n",
            "         weighted avg       0.97      0.96      0.96       431\n",
            "\n",
            "\n",
            "✅ Saved potato model to: /content/models_out/potato_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from skimage.feature import hog\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "\n",
        "# -------------------------\n",
        "# Settings\n",
        "# -------------------------\n",
        "POTATO_ROOT = \"/content/data/PlantVillage\"     \n",
        "CROP_PREFIX = \"Potato___\"\n",
        "OUT_PKL = \"/content/models_out/potato_model.pkl\"\n",
        "os.makedirs(\"/content/models_out\", exist_ok=True)\n",
        "\n",
        "EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
        "\n",
        "# -------------------------\n",
        "# Feature extraction\n",
        "# -------------------------\n",
        "def extract_features(img_bgr, size=(128,128)):\n",
        "    img = cv2.resize(img_bgr, size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    hog_feat = hog(\n",
        "        gray,\n",
        "        orientations=9,\n",
        "        pixels_per_cell=(8,8),\n",
        "        cells_per_block=(2,2),\n",
        "        block_norm=\"L2-Hys\",\n",
        "        feature_vector=True\n",
        "    )\n",
        "\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv],[0,1,2],None,[8,8,8],[0,180,0,256,0,256]).flatten()\n",
        "    hist = hist / (hist.sum() + 1e-8)\n",
        "\n",
        "    return np.concatenate([hog_feat, hist]).astype(np.float32)\n",
        "\n",
        "# -------------------------\n",
        "# Load Potato classes\n",
        "# -------------------------\n",
        "def load_potato_dataset(root_dir, prefix=\"Potato___\", limit_per_class=None):\n",
        "    root = Path(root_dir)\n",
        "    if not root.exists():\n",
        "        raise FileNotFoundError(root_dir)\n",
        "\n",
        "    class_dirs = [d for d in root.iterdir() if d.is_dir() and d.name.lower().startswith(prefix.lower())]\n",
        "    if len(class_dirs) < 2:\n",
        "        raise ValueError(f\"Not enough Potato classes found in {root_dir}\")\n",
        "\n",
        "    print(\"Detected Potato classes:\")\n",
        "    for d in class_dirs:\n",
        "        print(\" -\", d.name)\n",
        "\n",
        "    X, y = [], []\n",
        "    for cdir in class_dirs:\n",
        "        imgs = [f for f in cdir.rglob(\"*\") if f.is_file() and f.suffix.lower() in EXTS]\n",
        "        if limit_per_class:\n",
        "            imgs = imgs[:limit_per_class]\n",
        "\n",
        "        for fp in imgs:\n",
        "            img = cv2.imread(str(fp))\n",
        "            if img is None:\n",
        "                continue\n",
        "            X.append(extract_features(img))\n",
        "            y.append(cdir.name)\n",
        "\n",
        "    return np.array(X, dtype=np.float32), np.array(y)\n",
        "\n",
        "# -------------------------\n",
        "# Train + save best ML model\n",
        "# -------------------------\n",
        "def train_potato_model():\n",
        "    X, y = load_potato_dataset(POTATO_ROOT, CROP_PREFIX, limit_per_class=None)\n",
        "    print(\"\\nTotal samples:\", len(y), \"Feature dim:\", X.shape[1])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = scaler.fit_transform(X_train)\n",
        "    X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "    models = {\n",
        "        \"LinearSVC\": LinearSVC(),\n",
        "        \"LogReg\": LogisticRegression(max_iter=5000),\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
        "    }\n",
        "\n",
        "    best_name, best_acc, best_model = None, -1, None\n",
        "\n",
        "    for name, m in models.items():\n",
        "        if name == \"RandomForest\":\n",
        "            m.fit(X_train, y_train)\n",
        "            pred = m.predict(X_test)\n",
        "        else:\n",
        "            m.fit(X_train_s, y_train)\n",
        "            pred = m.predict(X_test_s)\n",
        "\n",
        "        acc = accuracy_score(y_test, pred)\n",
        "        print(f\"{name} accuracy: {acc:.4f}\")\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_name, best_model = acc, name, m\n",
        "\n",
        "    # Best model report\n",
        "    if best_name == \"RandomForest\":\n",
        "        pred = best_model.predict(X_test)\n",
        "    else:\n",
        "        pred = best_model.predict(X_test_s)\n",
        "\n",
        "    print(\"\\nBest model:\", best_name, \"Acc:\", best_acc)\n",
        "    print(classification_report(y_test, pred, target_names=le.classes_))\n",
        "\n",
        "    bundle = {\n",
        "        \"crop\": \"potato\",\n",
        "        \"model_name\": best_name,\n",
        "        \"model\": best_model,\n",
        "        \"scaler\": scaler,\n",
        "        \"label_encoder\": le,\n",
        "        \"dataset_root\": POTATO_ROOT,\n",
        "        \"class_prefix\": CROP_PREFIX,\n",
        "        \"feature_info\": {\"img_size\": (128,128), \"hog\": \"9 ori, 8x8, 2x2\", \"hsv_hist\": (8,8,8)},\n",
        "    }\n",
        "\n",
        "    joblib.dump(bundle, OUT_PKL)\n",
        "    print(\"\\nSaved potato model to:\", OUT_PKL)\n",
        "\n",
        "train_potato_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model for Tomato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RHHhX7DRB3E",
        "outputId": "cc052d95-eace-46f0-e2d2-ed220431fd35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN_DIR: /content/data/train\n",
            "TEST_DIR : /content/data/test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features from train: 100%|██████████| 8000/8000 [01:09<00:00, 115.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved cache: /content/models_out/tomato_train_feats.npz  X=(8000, 4868), y=(8000,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features from test: 100%|██████████| 2000/2000 [00:15<00:00, 132.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved cache: /content/models_out/tomato_test_feats.npz  X=(2000, 4868), y=(2000,)\n",
            "Train samples: 8000\n",
            "Test samples : 2000\n",
            "\n",
            "--- Training LinearSVC ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearSVC test accuracy: 0.8340\n",
            "\n",
            "--- Training LogReg ---\n",
            "LogReg test accuracy: 0.8665\n",
            "\n",
            "--- Training RandomForest ---\n",
            "RandomForest test accuracy: 0.9160\n",
            "\n",
            "--- Training KNN ---\n",
            "KNN test accuracy: 0.5020\n",
            "\n",
            "✅ Best model: RandomForest Test Acc: 0.916\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        bacterial_spot       0.92      0.94      0.93       200\n",
            "          early_blight       0.87      0.65      0.74       200\n",
            "               healthy       0.97      0.95      0.96       200\n",
            "           late_blight       0.82      0.84      0.83       200\n",
            "             leaf_mold       0.96      0.98      0.97       200\n",
            "          mosaic_virus       0.98      0.98      0.98       200\n",
            "    septoria_leaf_spot       0.89      0.97      0.93       200\n",
            "           target_spot       0.91      0.90      0.90       200\n",
            "twospotted_spider_mite       0.90      0.97      0.93       200\n",
            "yellow_leaf_curl_virus       0.93      0.98      0.96       200\n",
            "\n",
            "              accuracy                           0.92      2000\n",
            "             macro avg       0.92      0.92      0.91      2000\n",
            "          weighted avg       0.92      0.92      0.91      2000\n",
            "\n",
            "✅ Saved: /content/models_out/tomato_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from skimage.feature import hog\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "\n",
        "EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
        "\n",
        "# SET THIS base folder (must contain train/ and test/)\n",
        "TOMATO_BASE = \"/content/data\"    # your screenshot shows /content/data/train and /content/data/test\n",
        "TRAIN_DIR = os.path.join(TOMATO_BASE, \"train\")\n",
        "TEST_DIR  = os.path.join(TOMATO_BASE, \"test\")\n",
        "\n",
        "OUT_PKL = \"/content/models_out/tomato_model.pkl\"\n",
        "CACHE_TRAIN = \"/content/models_out/tomato_train_feats.npz\"\n",
        "CACHE_TEST  = \"/content/models_out/tomato_test_feats.npz\"\n",
        "os.makedirs(\"/content/models_out\", exist_ok=True)\n",
        "\n",
        "# ---------- Feature extraction ----------\n",
        "def extract_features(img_bgr, size=(96, 96)):   # ✅ smaller size = faster\n",
        "    img = cv2.resize(img_bgr, size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    hog_feat = hog(\n",
        "        gray, orientations=9, pixels_per_cell=(8,8),\n",
        "        cells_per_block=(2,2), block_norm=\"L2-Hys\", feature_vector=True\n",
        "    )\n",
        "\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv],[0,1,2],None,[8,8,8],[0,180,0,256,0,256]).flatten()\n",
        "    hist = hist / (hist.sum() + 1e-8)\n",
        "\n",
        "    return np.concatenate([hog_feat, hist]).astype(np.float32)\n",
        "\n",
        "def list_class_folders(root_dir):\n",
        "    root = Path(root_dir)\n",
        "    if not root.exists():\n",
        "        raise FileNotFoundError(root_dir)\n",
        "    classes = [d for d in root.iterdir() if d.is_dir()]\n",
        "    if len(classes) < 2:\n",
        "        raise ValueError(f\"Not enough class folders in: {root_dir}\")\n",
        "    return classes\n",
        "\n",
        "def load_folder_dataset_with_progress(root_dir, limit_per_class=None):\n",
        "    class_dirs = list_class_folders(root_dir)\n",
        "\n",
        "    # Build file list first (so we can show global progress)\n",
        "    items = []\n",
        "    for cdir in class_dirs:\n",
        "        files = [f for f in cdir.rglob(\"*\") if f.is_file() and f.suffix.lower() in EXTS]\n",
        "        if limit_per_class:\n",
        "            files = files[:limit_per_class]\n",
        "        for fp in files:\n",
        "            items.append((str(fp), cdir.name))\n",
        "\n",
        "    if len(items) == 0:\n",
        "        raise ValueError(f\"No images found in: {root_dir}\")\n",
        "\n",
        "    X, y = [], []\n",
        "    for fp, label in tqdm(items, desc=f\"Extracting features from {Path(root_dir).name}\", total=len(items)):\n",
        "        img = cv2.imread(fp)\n",
        "        if img is None:\n",
        "            continue\n",
        "        X.append(extract_features(img))\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X, dtype=np.float32), np.array(y)\n",
        "\n",
        "def load_or_build_cache(cache_path, folder, limit_per_class=None):\n",
        "    if os.path.exists(cache_path):\n",
        "        data = np.load(cache_path, allow_pickle=True)\n",
        "        print(f\"Loaded cache: {cache_path}  X={data['X'].shape}, y={data['y'].shape}\")\n",
        "        return data[\"X\"], data[\"y\"]\n",
        "\n",
        "    X, y = load_folder_dataset_with_progress(folder, limit_per_class=limit_per_class)\n",
        "    np.savez_compressed(cache_path, X=X, y=y)\n",
        "    print(f\"Saved cache: {cache_path}  X={X.shape}, y={y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "# ---------- Load data (with cache) ----------\n",
        "# For quick run, set limit_per_class like 800 (train) and 200 (test)\n",
        "LIMIT_TRAIN_PER_CLASS = 800   # e.g. 800\n",
        "LIMIT_TEST_PER_CLASS  = 200   # e.g. 200\n",
        "\n",
        "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
        "print(\"TEST_DIR :\", TEST_DIR)\n",
        "\n",
        "X_train, y_train = load_or_build_cache(CACHE_TRAIN, TRAIN_DIR, limit_per_class=LIMIT_TRAIN_PER_CLASS)\n",
        "X_test,  y_test  = load_or_build_cache(CACHE_TEST,  TEST_DIR,  limit_per_class=LIMIT_TEST_PER_CLASS)\n",
        "\n",
        "print(\"Train samples:\", len(y_train))\n",
        "print(\"Test samples :\", len(y_test))\n",
        "\n",
        "# ---------- Encode labels ----------\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc  = le.transform(y_test)\n",
        "\n",
        "# ---------- Scale for linear models ----------\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "# ---------- Train models ----------\n",
        "models = {\n",
        "    \"LinearSVC\": LinearSVC(),\n",
        "    \"LogReg\": LogisticRegression(max_iter=5000),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=250, random_state=42, n_jobs=-1),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
        "}\n",
        "\n",
        "best_name, best_acc, best_model = None, -1, None\n",
        "\n",
        "for name, m in models.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "    if name == \"RandomForest\":\n",
        "        m.fit(X_train, y_train_enc)\n",
        "        pred = m.predict(X_test)\n",
        "    else:\n",
        "        m.fit(X_train_s, y_train_enc)\n",
        "        pred = m.predict(X_test_s)\n",
        "\n",
        "    acc = accuracy_score(y_test_enc, pred)\n",
        "    print(f\"{name} test accuracy: {acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc, best_name, best_model = acc, name, m\n",
        "\n",
        "# ---------- Final report ----------\n",
        "if best_name == \"RandomForest\":\n",
        "    final_pred = best_model.predict(X_test)\n",
        "else:\n",
        "    final_pred = best_model.predict(X_test_s)\n",
        "\n",
        "print(\"\\nBest model:\", best_name, \"Test Acc:\", best_acc)\n",
        "print(classification_report(y_test_enc, final_pred, target_names=le.classes_))\n",
        "\n",
        "# ---------- Save bundle ----------\n",
        "bundle = {\n",
        "    \"crop\": \"tomato\",\n",
        "    \"model_name\": best_name,\n",
        "    \"model\": best_model,\n",
        "    \"scaler\": scaler,\n",
        "    \"label_encoder\": le,\n",
        "    \"dataset_root\": TOMATO_BASE,\n",
        "    \"feature_info\": {\"img_size\": (96,96), \"hog\": \"9 ori, 8x8, 2x2\", \"hsv_hist\": (8,8,8)},\n",
        "}\n",
        "\n",
        "joblib.dump(bundle, OUT_PKL)\n",
        "print(\"Saved:\", OUT_PKL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the pkl zip files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "2R9G5lfFjp-J",
        "outputId": "df635d0c-b13b-47ae-e3e7-1fa375f096b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/models_out/jute_model.pkl (deflated 76%)\n",
            "  adding: content/models_out/potato_model.pkl (deflated 75%)\n",
            "  adding: content/models_out/rice_model.pkl (deflated 82%)\n",
            "  adding: content/models_out/tomato_model.pkl (deflated 85%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_99391433-2e68-479b-bcec-03e1aca9d823\", \"models_out.zip\", 17771915)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!zip -r models_out.zip /content/models_out/*.pkl\n",
        "from google.colab import files\n",
        "files.download(\"models_out.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
